---
layout: user_guide
title: Pangool - User guide - Mapred API
---
<div class="hero-unit">
	<h2>Pangool User Guide</h2>
</div>

<h2>Mapred API</h2>

<p>
The Pangool MapReduce API is formed by:
</p>

<ul>

	<li><strong>TupleMapper</strong> :
	</p>
	<p> Subclasses of this class will be ready to be used as Mappers in Pangool Jobs. This class requires two generic types: the ones that refer to the input format. This is because TupleMappers always emit (ITuple, NullWritable) as intermediate output, so we only need to add the types relative to the input format. 
	This class extends the standard Hadoop Mapper and has the usual methods: setup(), map() and cleanup().<p>
	</li> 

	<li><strong>TupleReducer</strong> : 
	</p>
	<p> Subclasses of this class will be ready to be used as Reducers in Pangool Jobs. This class requires two generic types: the ones that refer to the output format. This is because TupleReducers always receive ITuple groups and values from the intermediate output, so we only need to add the types relative to the output format.
	This class extends the standard Hadoop Reducer and has the usual methods: setup(), reducer() and cleanup(). 
	This class can also be used as a Combiner, given that the output types will be (ITuple, NullWritable).</p>
	</li>

	<li><strong>TupleRollupReducer</strong> :
	</p>
	<p>
	Reducer to be used when using rollup. It will have extra methods: onOpen(), onClose(). For information on rollup, check the “rollup” section in the user guide.</p></li>

	<li><strong>TupleRollupReducer</strong> :
	</p>
	<p>
	Reducer to be used when using rollup. It will have extra methods: onOpen(), onClose(). For information on rollup, check the “rollup” section in the user guide.</p></li>

	<li><strong>TupleMRBuilder</strong> :
	</p>
	<p>
	Use this class to create Job instances that use the Pangool API. The most important methods are:
	</p>
	<table>
	<tr><td>addIntermediateSchema</td><td>Allows the user to define intermediate Schemas. At least one must be defined. When performing Joins, more than one schema will be defined (see the Joins section for more information).</td></tr>
	<tr><td>addInput</td><td>Allows the user to add an input Path with an associated input format and TupleMapper. You can add an arbitrary number of inputs with this same method.</td></tr>
	<tr><td>addTupleInput</td><td>This method must be used when reading tuple inputs (files that were generated by Pangool jobs that wrote tuples as output).</td></tr>
	<tr><td>setOutput</td><td>Allows the user to define the Job’s main output Path and format.</td></tr>
	<tr><td>setTupleOutput</td><td>This method must be used when writing tuples as the main output of the Job. It will have an associated Schema so that Pangool knows how to write the Tuples.</td></tr>
	<tr><td>addNamedOutput</td><td>Same as setTupleOutput, but for named outputs.</td></tr>
	<tr><td>addNamedTupleOutput</td><td>Same as setTupleOutput, but for named outputs.</td></tr>
	<tr><td>setTupleReducer</td><td>Sets the TupleReducer instance to be used.</td></tr>
	<tr><td>setTupleCombiner</td><td>Sets the TupleReducer<ITuple, NullWritable> instance to be used as Combiner for the Job.</td></tr>
	<tr><td>setGroupByFields / setOrderBy</td><td>Configures how Pangool will sort and group by the intermediate tuples. For more info, check the “...” section.</td></tr>
	<tr><td>createJob()</td><td>Returns the Job instance read to be run.</td></tr>
	</table>		
	
	<li><strong>IdentityTupleMapper</strong> :
	</p>
	<p>
	Use this Mapper implementation when your Mapper only needs to emit the Tuples as they are being read (when using Tuple inputs).</p></li>

	<li><strong>IdentityTupleReducer</strong> :
	</p>
	<p>Use this Reducer implementation when your Reducer only needs to emit the Tuples as they are being received in the Reducer (including all the Tuples in the values’ Iterator).</p></li>	
</ul>
</p>
<p><a class="btn primary large" href="userguide3.html">Next: Group & Sort by &raquo;</a></p>