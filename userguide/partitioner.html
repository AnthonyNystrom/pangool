---
layout: user_guide
title: Pangool - User guide - Custom Partitioners
---
<div class="hero-unit">
	<h1>Pangool User Guide</h1>
</div>

<h1>Custom Partitioners</h1>

<p>
Usually the way Pangool partitions will be sufficient for almost all the cases. For jobs that don’t use <a href='userguide/rollup.html'>rollup</a>, Pangool will partition by a combined hash of the group by fields.
</p>

<p>
However, there are some cases where you’d want to partition by other fields (For instance, cases where you want to make your Job more parallelizable by shuffling the data and aggregating partial results in a second job afterwards). In this cases you can use the convenience method:
</p>

<pre class="prettyprint" id="java">
 grouper.setCustomPartitionFields(fields)
</pre>

<p>
This method will use a combined hash of the fields that you’ll pass. These fields must be present in the intermediate schema.
</p>

<p>
However if you wanted to create a custom, other than combined hash strategy, you’ll need to implement your own <a href='https://github.com/datasalt/pangool/blob/master/core/src/main/java/com/datasalt/pangool/tuplemr/mapred/TupleHashPartitioner.java'>org.apache.hadoop.mapreduce.Partitioner&lt;DatumWrapper&lt;ITuple&gt;, NullWritable&gt;</a> and assign it (using the Hadoop API) to the job that you create out of the <a href='userguide/TupleMrBuilder.html'>TupleMRBuilder</a>. Check the current Partitioner implementation in the Pangool source for a reference implementation.
</p>

<p><a class="btn btn-primary btn-large" href="comparators.html">Next: Custom Comparators &raquo;</a></p>